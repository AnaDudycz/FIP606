[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olá, seja bem-vindo(a) ao meu website!",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Githube\n  \n  \n    \n     Email\n  \n\n\n\n\nOlá, seja bem-vindo(a) ao meu website!\nMe chamo Ana Rita Dudycz, sou engenheira agrônoma pela Universidade Estadual do Centro-Oeste (UNICENTRO) e mestranda em fitopatologia na Universidade Federal de Viçosa (UFV).\nAqui você vai encontrar o material com anotações da disciplina análise e visualização de dados em fitopatologia, ofertada pelo Programa de Pós-Graduação em Fitopatologia da UFV.\nAproveite o conteúdo! Qualquer dúvida pode entrar em contato pelo meu e-mail."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula1.html",
    "href": "Aula1.html",
    "title": "Introdução ao R",
    "section": "",
    "text": "No programa R podemos inserir anotações e formatar o documento como um documento de texto. Para colocar uma palavra em negrito adiciona-se dois asteriscos antes e após a palavra (** **), e um anterisco antes e após a palavra (* *), para colocar uma palavra em itálico. O tamanho da fonte pode ser regulada pela quantidade de #."
  },
  {
    "objectID": "Aula1.html#introdução-ao-r",
    "href": "Aula1.html#introdução-ao-r",
    "title": "Aula 1",
    "section": "",
    "text": "No programa R podemos inserir anotações e formatar o documento como um documento de texto. Para colocar uma palavra em negrito adiciona-se dois asteriscos antes e após a palavra (** **), e um anterisco antes e após a palavra (* *), para colocar uma palavra em itálico. O tamanho da fonte pode ser regulada pela quantidade de #."
  },
  {
    "objectID": "Aula1.html#r-markdown",
    "href": "Aula1.html#r-markdown",
    "title": "Introdução ao R",
    "section": "R markdown",
    "text": "R markdown\nFormato que permite trabalhar com chunks separados e fazer o uso de anotações entre os mesmos. Pode-se inserir anotações úteis na análise do projeto. Um chunk é a área onde os códigos são inseridos e é possível rodar as análises. Para adicionar um chunk pode-se clicar em Ctrl+Alt+I.\n\nx &lt;- 10\ny &lt;- x * 10 \nz &lt;- x * y\nx &lt;- 10"
  },
  {
    "objectID": "Aula1.html#data.frame",
    "href": "Aula1.html#data.frame",
    "title": "Introdução ao R",
    "section": "Data.Frame",
    "text": "Data.Frame\nA função data.frame pode ser usada para organizar os dados trabalhados em uma tabela.\n\ndf &lt;- cars\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ndf$dist\n\n [1]   2  10   4  22  16  10  18  26  34  17  28  14  20  24  28  26  34  34  46\n[20]  26  36  60  80  20  26  54  32  40  32  40  50  42  56  76  84  36  46  68\n[39]  32  48  52  56  64  66  54  70  92  93 120  85\n\ndf$dist2 &lt;- c(1:50)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf |&gt; \n  mutate(dist3 = dist2+1) |&gt; \n  select(4)\n\n   dist3\n1      2\n2      3\n3      4\n4      5\n5      6\n6      7\n7      8\n8      9\n9     10\n10    11\n11    12\n12    13\n13    14\n14    15\n15    16\n16    17\n17    18\n18    19\n19    20\n20    21\n21    22\n22    23\n23    24\n24    25\n25    26\n26    27\n27    28\n28    29\n29    30\n30    31\n31    32\n32    33\n33    34\n34    35\n35    36\n36    37\n37    38\n38    39\n39    40\n40    41\n41    42\n42    43\n43    44\n44    45\n45    46\n46    47\n47    48\n48    49\n49    50\n50    51"
  },
  {
    "objectID": "Aula1.html#instalando-pacotes",
    "href": "Aula1.html#instalando-pacotes",
    "title": "Introdução ao R",
    "section": "Instalando pacotes",
    "text": "Instalando pacotes\nHá diferentes formas de instalar pacotes. No source pode-se escrever o código Install.packages(“nome do pacote”). Para utilizar o pacote é necessário carregar o pacote com a função library(nome do pacote)\n\ninstall.packages(\"tidyverse\")\n\nWarning: package 'tidyverse' is in use and will not be installed\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "Aula1.html#utilizando-o-pacote-ec50estimator",
    "href": "Aula1.html#utilizando-o-pacote-ec50estimator",
    "title": "Introdução ao R",
    "section": "Utilizando o pacote ec50estimator",
    "text": "Utilizando o pacote ec50estimator\nCom o pacote ec50estimator pode-se estimar a dose efetiva a partir de um conjunto de dados. Pode -se observar um exemplo chamado multi_isolate dentro do pacote, em que há um conjunto de dados relacionando o crescimento micelial a partir de diferentes doses de fungicidas.\n\n##install.packages(\"ec50estimator\")\nlibrary (ec50estimator)\ndf1 &lt;- multi_isolate"
  },
  {
    "objectID": "Aula1.html#aprendendo-como-inserir-texto-ou-códigos-no-r",
    "href": "Aula1.html#aprendendo-como-inserir-texto-ou-códigos-no-r",
    "title": "Introdução ao R",
    "section": "",
    "text": "No programa R podemos inserir anotações e formatar o documento como um documento de texto. Para colocar uma palavra em negrito adiciona-se dois asteriscos antes e após a palavra (** **), e um anterisco antes e após a palavra (* *), para colocar uma palavra em itálico. O tamanho da fonte pode ser regulada pela quantidade de #."
  },
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "",
    "text": "Primeiramente é necessário adicionar a planilha com os dados, dentro da pasta com o projeto de trabalho. Em seguida instalar e carregar o pacote readxl. Para corregar a planilha é necessário usar a função read_excel() e inserir o nome completo do arquivo incluindo o .xlsx, entre aspas. Se houver mais de uma planilha dentro do arquivo excel é necessário indicar qual a planilha deseja-se adicionar, deve-se adicionar o argumento sheet = número da ordem da planilha.\n\n##install.packages(\"readxl\")\nlibrary(readxl)\n\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = 2)"
  },
  {
    "objectID": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-excel",
    "href": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-excel",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "",
    "text": "Primeiramente é necessário adicionar a planilha com os dados, dentro da pasta com o projeto de trabalho. Em seguida instalar e carregar o pacote readxl. Para corregar a planilha é necessário usar a função read_excel() e inserir o nome completo do arquivo incluindo o .xlsx, entre aspas. Se houver mais de uma planilha dentro do arquivo excel é necessário indicar qual a planilha deseja-se adicionar, deve-se adicionar o argumento sheet = número da ordem da planilha.\n\n##install.packages(\"readxl\")\nlibrary(readxl)\n\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = 2)"
  },
  {
    "objectID": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-um-arquivo-de-texto-csv",
    "href": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-um-arquivo-de-texto-csv",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "Abrindo conjunto de dados a partir de um arquivo de texto (csv)",
    "text": "Abrindo conjunto de dados a partir de um arquivo de texto (csv)\nO processo é o mesmo do arquivo xlsx, basta adicionar o aquivo no formato csv na pasta do projeto. O pacote a ser usado é o tidyverse e a função read.csv().\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf3 &lt;- read.csv(\"dados-diversos.csv\")"
  },
  {
    "objectID": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-google",
    "href": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-google",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "Abrindo conjunto de dados a partir de uma planilha google",
    "text": "Abrindo conjunto de dados a partir de uma planilha google\nCom o pacote gsheet e a função gsheet2tbl é possivel carregar uma planilha google apenas com o link desta.Também é possível fazer o carregamento com o pacote googlesheets4 e a função read_sheet.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\n\nlibrary (googlesheets4)\ndf5 &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")\n\n! Using an auto-discovered, cached token.\n\n\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n\n\n  See gargle's \"Non-interactive auth\" vignette for more details:\n\n\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n\n\nℹ The googlesheets4 package is using a cached token for 'ana.dudycz@ufv.br'.\n\n\nAuto-refreshing stale OAuth token.\n\n\n✔ Reading from \"dados-diversos\".\n\n\n✔ Range 'magnesio'."
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Gráficos com ggplot",
    "section": "",
    "text": "Com o pacote ggplot2 e a função ggploté possivel criar gráficos a partir da planilha carregada anteriormente. Com este pacote é possível escolher o tipo de gráfico como o geom_boxplot no exemplo abaixo e personalizar da maneira desejada, com comandos e argumentos necessários, pode-se ajusta a cor, distâncias e tamanho das linhas e barras, adicionar legenda e formatar os eixos. Para salvar o gráfico gerado a função ggsave pode ser utilizada.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\nlibrary(ggplot2)\nlibrary(ggthemes)\ng1 &lt;- df4 |&gt; \n  ggplot(aes(x = trat, y = comp)) +\n  geom_boxplot(outlier.colour = NA,\n               fill = \"green\")+\n  geom_jitter(width = 0.05,\n              color = 'black',\n              shape = 2,\n              size = 3)+\n  theme_clean()+\n  labs (x = \"tratamento\",\n       y = \"comprimento (mm)\",\n       title = \"Meu primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")\ng1\n\n\n\n#ylim(0,20)+\n  scale_y_continuous(limits = c(5,20),\n                     n.breaks =10)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    5 --   20\n\n  ggsave(\"plot1.png\", bg = \"white\")\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "Aula3.html#constução-de-gráficos",
    "href": "Aula3.html#constução-de-gráficos",
    "title": "Gráficos com ggplot",
    "section": "",
    "text": "Com o pacote ggplot2 e a função ggploté possivel criar gráficos a partir da planilha carregada anteriormente. Com este pacote é possível escolher o tipo de gráfico como o geom_boxplot no exemplo abaixo e personalizar da maneira desejada, com comandos e argumentos necessários, pode-se ajusta a cor, distâncias e tamanho das linhas e barras, adicionar legenda e formatar os eixos. Para salvar o gráfico gerado a função ggsave pode ser utilizada.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\nlibrary(ggplot2)\nlibrary(ggthemes)\ng1 &lt;- df4 |&gt; \n  ggplot(aes(x = trat, y = comp)) +\n  geom_boxplot(outlier.colour = NA,\n               fill = \"green\")+\n  geom_jitter(width = 0.05,\n              color = 'black',\n              shape = 2,\n              size = 3)+\n  theme_clean()+\n  labs (x = \"tratamento\",\n       y = \"comprimento (mm)\",\n       title = \"Meu primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")\ng1\n\n\n\n#ylim(0,20)+\n  scale_y_continuous(limits = c(5,20),\n                     n.breaks =10)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    5 --   20\n\n  ggsave(\"plot1.png\", bg = \"white\")\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "Aula3.html#importando-os-dados-com-o-pacote-tidyverse",
    "href": "Aula3.html#importando-os-dados-com-o-pacote-tidyverse",
    "title": "Gráficos com ggplot",
    "section": "Importando os dados com o pacote tidyverse",
    "text": "Importando os dados com o pacote tidyverse\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nRows: 405 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): region, zone, district, cultivar, shade, cropping_system, farm_mana...\ndbl (6): farm, lon, lat, altitude, inc, sev2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…"
  },
  {
    "objectID": "Aula3.html#trabalhando-os-dados",
    "href": "Aula3.html#trabalhando-os-dados",
    "title": "Gráficos com ggplot",
    "section": "Trabalhando os dados",
    "text": "Trabalhando os dados\nPara visualizar os dados do conjunto chamado cr, os dados foram agrupados com a função group_by(), posteriormente Calculada a média com o comando mean(), os resultados visualizados com ggplot.\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\ncr |&gt;\n  group_by(cultivar) |&gt;\n    summarize(inc_mean = mean(inc),\nsd_mean = sd(inc))\n\n# A tibble: 3 × 3\n  cultivar inc_mean sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4    5.66\n2 Local        53.4   14.3 \n3 Mixture      31.9   11.2 \n\ncr |&gt;\n  ggplot(aes(x=inc))+\n  geom_histogram()+\n  facet_grid(region~cultivar)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "Aula3.html#usando-as-funções-para-sumarizar",
    "href": "Aula3.html#usando-as-funções-para-sumarizar",
    "title": "Gráficos com ggplot",
    "section": "Usando as funções para sumarizar",
    "text": "Usando as funções para sumarizar\nA função summarize () é utilizada para criar novas variáveis a partir do conjunto de dados já agrupados.\n\ncr |&gt;\n group_by(region) |&gt;\n    summarize(sev_med = median(sev2),\n              sev_mean = mean(sev2),\n              sev_sd = sd(sev2))\n\n# A tibble: 2 × 4\n  region sev_med sev_mean sev_sd\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Oromia    6.23     8.06   6.82\n2 SNNPR     4.88     9.81  10.5 \n\ncr |&gt;\n  ggplot(aes(inc,sev2))+\n  geom_point()"
  },
  {
    "objectID": "Aula3.html#visualizando-os-dados",
    "href": "Aula3.html#visualizando-os-dados",
    "title": "Gráficos com ggplot",
    "section": "Visualizando os dados",
    "text": "Visualizando os dados\n\nlibrary(ggthemes)\ncr |&gt;\n  ggplot(aes(x =sev2, fill = region))+\n  geom_histogram(color = \"white\")+\n  facet_wrap(region ~ cultivar, ncol = 6)+\n  scale_fill_manual(values = c(\"black\", \"brown\"))+\n  theme_minimal(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\", fill= \"Region\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n#ggsave(\"crl.png\", bg = \"white\")"
  },
  {
    "objectID": "Aula3.html#criando-subconjuntos",
    "href": "Aula3.html#criando-subconjuntos",
    "title": "Gráficos com ggplot",
    "section": "Criando subconjuntos",
    "text": "Criando subconjuntos\nO pacote dplyr possui funções que ajudam na manipulação dos dados e facilitam a visualização, como a função select() que seleciona as coluna de um dataframe e a função filter() que permite-se fazer a filtragem das linhas do conjunto.\n\n# filtra Oromia\ncr_oromia &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt;\n  filter(region == \"Oromia\")\n\n# filtra SNNPR\ncr_pr &lt;- cr|&gt;\n  select(farm, region, cultivar, sev2) |&gt;\n  filter(region == \"SNNPR\")\n\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows"
  },
  {
    "objectID": "Aula3.html#visualizando-os-subconjuntos",
    "href": "Aula3.html#visualizando-os-subconjuntos",
    "title": "Gráficos com ggplot",
    "section": "Visualizando os subconjuntos",
    "text": "Visualizando os subconjuntos\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(cultivar, sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few()+\n  scale_fill_few()+\n  labs(x = \"\",\n       y = \"Severity (%)\")+\n    coord_flip()\n\np2 &lt;- cr_pr |&gt;\n  ggplot(aes(cultivar, sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few()+\n  scale_fill_few()+\n  labs(x = \"\",\n       y = \"Severity (%)\")+\n    coord_flip()\n\np1\n\n\n\np2\n\n\n\nlibrary(patchwork)\n\np1 + p2 +\n  plot_layout(guides = 'collect',\n  axes = 'collect')+\n  plot_annotation(title = \"Coffe rust in Ethiopia\",\n                  caption = \"Source: Dudycz (2024)\")\n\n\n\n  plot_annotation(tag_levels = 'A')\n\n$title\nNULL\n\n$subtitle\nNULL\n\n$caption\nNULL\n\n$tag_levels\n[1] \"A\"\n\n$tag_prefix\nNULL\n\n$tag_suffix\nNULL\n\n$tag_sep\nNULL\n\n$theme\n Named list()\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nattr(,\"class\")\n[1] \"plot_annotation\"\n\nggsave(\"patch1.png\", width = 6,\n       height = 4)\n\np3 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram()\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\np1/ (p2 + p1)"
  },
  {
    "objectID": "Aula4.html",
    "href": "Aula4.html",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "",
    "text": "O vetor ‘comp’ que contém 20 valores numéricos representando a concentração do composto em diferentes experimentos. O objeto data.table em R armazena os dados experimentais sobre a concentração de um composto (comp) em diferentes tratamentos (trat) e repetições (rep).\n\ncomp &lt;- (c(9, 12.5, 10, 8, 13.2, 11, 10.8, 9.5, 10.8, 10.4, 13.72, 15.91, 15.7, 14.2, 15.9, 16.54, 18, 14.4, 16.41, 16)\n)\n\ndata.table::data.table(\n        trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                 \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\"control\",\"control\",\n                 \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                 \"control\"),\n         rep = c(1L,2L,3L,4L,5L,6L,7L,8L,9L,10L,1L,\n                 2L,3L,4L,5L,6L,7L,8L,9L,10L),\n        comp = c(9,12.5,10,8,13.2,11,10.8,9.5,10.8,\n                 10.4,13.72,15.91,15.7,14.2,15.9,16.54,18,14.4,16.41,\n                 16)\n)\n\n       trat   rep  comp\n     &lt;char&gt; &lt;int&gt; &lt;num&gt;\n 1:     Mg2     1  9.00\n 2:     Mg2     2 12.50\n 3:     Mg2     3 10.00\n 4:     Mg2     4  8.00\n 5:     Mg2     5 13.20\n 6:     Mg2     6 11.00\n 7:     Mg2     7 10.80\n 8:     Mg2     8  9.50\n 9:     Mg2     9 10.80\n10:     Mg2    10 10.40\n11: control     1 13.72\n12: control     2 15.91\n13: control     3 15.70\n14: control     4 14.20\n15: control     5 15.90\n16: control     6 16.54\n17: control     7 18.00\n18: control     8 14.40\n19: control     9 16.41\n20: control    10 16.00\n       trat   rep  comp"
  },
  {
    "objectID": "Aula4.html#usando-datapasta-de-dados-a-partir-de-uma-tabela-google",
    "href": "Aula4.html#usando-datapasta-de-dados-a-partir-de-uma-tabela-google",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "",
    "text": "O vetor ‘comp’ que contém 20 valores numéricos representando a concentração do composto em diferentes experimentos. O objeto data.table em R armazena os dados experimentais sobre a concentração de um composto (comp) em diferentes tratamentos (trat) e repetições (rep).\n\ncomp &lt;- (c(9, 12.5, 10, 8, 13.2, 11, 10.8, 9.5, 10.8, 10.4, 13.72, 15.91, 15.7, 14.2, 15.9, 16.54, 18, 14.4, 16.41, 16)\n)\n\ndata.table::data.table(\n        trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                 \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\"control\",\"control\",\n                 \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                 \"control\"),\n         rep = c(1L,2L,3L,4L,5L,6L,7L,8L,9L,10L,1L,\n                 2L,3L,4L,5L,6L,7L,8L,9L,10L),\n        comp = c(9,12.5,10,8,13.2,11,10.8,9.5,10.8,\n                 10.4,13.72,15.91,15.7,14.2,15.9,16.54,18,14.4,16.41,\n                 16)\n)\n\n       trat   rep  comp\n     &lt;char&gt; &lt;int&gt; &lt;num&gt;\n 1:     Mg2     1  9.00\n 2:     Mg2     2 12.50\n 3:     Mg2     3 10.00\n 4:     Mg2     4  8.00\n 5:     Mg2     5 13.20\n 6:     Mg2     6 11.00\n 7:     Mg2     7 10.80\n 8:     Mg2     8  9.50\n 9:     Mg2     9 10.80\n10:     Mg2    10 10.40\n11: control     1 13.72\n12: control     2 15.91\n13: control     3 15.70\n14: control     4 14.20\n15: control     5 15.90\n16: control     6 16.54\n17: control     7 18.00\n18: control     8 14.40\n19: control     9 16.41\n20: control    10 16.00\n       trat   rep  comp"
  },
  {
    "objectID": "Aula4.html#dados-a-partir-da-web",
    "href": "Aula4.html#dados-a-partir-da-web",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "Dados a partir da web",
    "text": "Dados a partir da web\nA função tribble() do pacote tibble também pode ser usada para organizar os dados em uma tabela.\n\ntibble::tribble(\n  ~`1`,          ~Brazil, ~`4,303`,\n    2L,     \"Mozambique\",      43L,\n    3L,       \"Portugal\",      33L,\n    4L,  \"United States\",      23L,\n    5L,         \"Angola\",      19L,\n    6L,          \"Spain\",      16L,\n    7L,      \"(not set)\",      12L,\n    8L,       \"Colombia\",       8L,\n    9L,        \"Germany\",       5L,\n   10L,        \"Hungary\",       5L,\n   11L, \"United Kingdom\",       5L,\n   12L,    \"Netherlands\",       4L,\n   13L,        \"Ecuador\",       3L,\n   14L,         \"France\",       3L,\n   15L,          \"Chile\",       2L,\n   16L,       \"Paraguay\",       2L,\n   17L,           \"Peru\",       2L,\n   18L,      \"Argentina\",       1L,\n   19L,        \"Austria\",       1L,\n   20L,        \"Bolivia\",       1L,\n   21L,     \"Cape Verde\",       1L,\n   22L,          \"China\",       1L,\n   23L,          \"Egypt\",       1L,\n   24L,        \"Finland\",       1L,\n   25L,          \"India\",       1L,\n   26L,          \"Italy\",       1L,\n   27L,       \"Malaysia\",       1L,\n   28L,       \"Pakistan\",       1L,\n   29L,         \"Poland\",       1L,\n   30L,      \"Singapore\",       1L,\n   31L,    \"Timor-Leste\",       1L,\n   32L,        \"Uruguay\",       1L\n  )\n\n# A tibble: 31 × 3\n     `1` Brazil         `4,303`\n   &lt;int&gt; &lt;chr&gt;            &lt;int&gt;\n 1     2 Mozambique          43\n 2     3 Portugal            33\n 3     4 United States       23\n 4     5 Angola              19\n 5     6 Spain               16\n 6     7 (not set)           12\n 7     8 Colombia             8\n 8     9 Germany              5\n 9    10 Hungary              5\n10    11 United Kingdom       5\n# ℹ 21 more rows\n\n\nO pacote tiyverse pode ser usado para a remodelagem dos dados. A função pivot_longer() permite passar os dados do formato largo para o formato longo. A função annotate do pacote ggplot2 em R é usada para adicionar anotações personalizadas aos gráficos, como textos para destacar ou explicar partes específicas de um gráfico.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  )\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt;\n  ggplot(aes(t, inc, color = epidemic)) +\n  geom_point() +\n  geom_line() +\n  annotate(geom = \"text\",\n           x = 12,\n           y = 0.75,\n           label =\"1\")+\n annotate(geom = \"text\",\n           x = 25,\n           y = 0.75,\n           label =\"2\")+\n   annotate(geom = \"text\",\n           x = 47,\n           y = 0.75,\n           label =\"3\")+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Aula4.html#tabela-de-contingência",
    "href": "Aula4.html#tabela-de-contingência",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "Tabela de contingência",
    "text": "Tabela de contingência\nUma tabela de contingência é uma forma de resumir e visualizar a distribuição conjunta de duas ou mais variáveis categóricas. Ela mostra como as frequências ou contagens são distribuídas entre as diferentes categorias de cada uma das variáveis, permitindo analisar relações e associações entre elas.\no conjunto de dados cr que foi lido do arquivo CSV e usar o pacote janitor para criar uma tabela de contingência e ggplot2 para criar gráficos.\ncriou-se uma tabela de contingência para as variáveis cultivar e farm_management usando tabyl.\n\nlibrary(ggthemes)\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nRows: 405 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): region, zone, district, cultivar, shade, cropping_system, farm_mana...\ndbl (6): farm, lon, lat, altitude, inc, sev2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncr |&gt;\n  count(farm_management, cultivar) |&gt;\n  ggplot(aes(cultivar, n, fill = farm_management,\n             label = n)) +\n  geom_col(position = \"dodge2\")+\n  scale_fill_colorblind()+\n  theme_bw()+\n  theme(strip.text.x=element_blank(),\n        legend.position = \"top\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")\n\n\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ncr |&gt;\n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0"
  },
  {
    "objectID": "Aula4.html#geom_errorbar",
    "href": "Aula4.html#geom_errorbar",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "geom_errorbar",
    "text": "geom_errorbar\nO geom_errorbar() é uma função do pacote ggplot2 que permite adicionar barras de erro a um gráfico. Essas barras de erro são frequentemente usadas para representar a variabilidade ou incerteza associada às medições feitas em um conjunto de dados.\n\nlibrary(gsheet)\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nmg |&gt;\n  group_by(trat) |&gt;\n  summarise(mean_comp = mean(comp)) |&gt;\n  ggplot(aes(trat,mean_comp))+\n  geom_col(fill = \"steelblue\", width =0.5)\n\n\n\ngeom_errorbar(aes(ymin = mean_comp - sd_comp,\n                  ymax = mean_comp + sd_comp),\n              width = 0.1)\n\nmapping: ymin = ~mean_comp - sd_comp, ymax = ~mean_comp + sd_comp \ngeom_errorbar: na.rm = FALSE, orientation = NA, width = 0.1\nstat_identity: na.rm = FALSE\nposition_identity \n\nmg |&gt;\n  group_by(trat) |&gt;\n  summarise(\n    mean_comp = mean(comp),\n    sd_comp = sd(comp)) |&gt;\n  ggplot(aes(x = trat, y = mean_comp)) +\n  geom_point(size = 3) +\n  ylim(5, 20) +\n  geom_errorbar(aes(ymin = mean_comp - sd_comp, ymax = mean_comp + sd_comp), width = 0.2) +\n  annotate(geom = \"text\", x = 1, y = 17.5, label = \"*\")\n\n\n\nmg |&gt;\n  ggplot(aes(trat,comp))+\n  geom_jitter(width =0.1)"
  },
  {
    "objectID": "Aula5.html",
    "href": "Aula5.html",
    "title": "Teste T",
    "section": "",
    "text": "Carregamento dos dados a partir da planilha google.\n\nlibrary(gsheet)\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")"
  },
  {
    "objectID": "Aula5.html#importando-os-dados",
    "href": "Aula5.html#importando-os-dados",
    "title": "Teste T",
    "section": "",
    "text": "Carregamento dos dados a partir da planilha google.\n\nlibrary(gsheet)\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")"
  },
  {
    "objectID": "Aula5.html#visualização-dos-dados",
    "href": "Aula5.html#visualização-dos-dados",
    "title": "Teste T",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nO gráfico em Boxplot mostra se a distribuição dos dados se aproxima de uma distribuição normal, o valor das medianas destacadas dentro do box mostra o efeito da distribuíção.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmg |&gt;\n  ggplot(aes(trat,comp))+\n  geom_boxplot()"
  },
  {
    "objectID": "Aula5.html#teste-t",
    "href": "Aula5.html#teste-t",
    "title": "Teste T",
    "section": "Teste T",
    "text": "Teste T\nPara testar grupos independentes pode-se utilizar o teste T (função t.test). Este é um teste simples, que assume duas premissas: primeira, que a distribuição é normal (pode-se observar pela simetria do box) e segunda, que as variâncias são homogêneas. a função pivot_wider() pode ser usada para passar a planilha do formato largo para o longo.\nO valor do teste T depende da variabilidade dos dados. Quanto mais negativo é o valor de T, menor vai ser o p-valor. O p-valor é o valor da probabilidade dada a hipótese nula de encontrar o valor de uma certa magnitetude.\nNo caso de dados com variâncias homogêneas, adiciona-se o comando var.equal = TRUE (para dados homogêneos é opcional o uso deste comando). Já para variâncias heterogêneas deve-se adicionar o comando var.equal = FALSE (obrigatório).\nApós a análise do teste, deve-se observar se houve diferença estatistíca. De acordo com os resultados btidos deve-se determinar se os resultado do teste T são confiáveis.\nPara obter a confirmação de que a distribuição dos dados é normal pode-se utilizar um teste de normalidade (função shapiro.test())\nO comando report() relata a saida do teste T.\n\nmg2 &lt;- mg |&gt;\n  pivot_wider(names_from = trat,\n              values_from = comp)\nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\nteste1 &lt;- t.test(mg2$control, mg2$Mg2,\n       var.equal = TRUE)\nteste1\n\n\n    Two Sample t-test\n\ndata:  mg2$control and mg2$Mg2\nt = 8.1549, df = 18, p-value = 1.863e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.829161 6.486839\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\nhist(mg2$control)\n\n\n\nhist(mg2$Mg2)\n\n\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n\n\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Two Sample t-test testing the difference between mg2$control and mg2$Mg2\n(mean of x = 15.68, mean of y = 10.52) suggests that the effect is positive,\nstatistically significant, and large (difference = 5.16, 95% CI [3.83, 6.49],\nt(18) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.16, 5.10])\n\n\nPara a comparação dos dados com mais de dois grupos distintos, pode-se utilizar o teste F. Após visualizar os dados no box, pode-se ter a confirmação de que as variâncias são homgenêneas com o test F."
  },
  {
    "objectID": "Aula5.html#dois-grupos-dependentes",
    "href": "Aula5.html#dois-grupos-dependentes",
    "title": "Teste T",
    "section": "Dois grupos dependentes",
    "text": "Dois grupos dependentes\nTeste T para teste pareado com dois grupos (o anterior foi um teste não pareado).\nDados importados:\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nVisualização em boxplot:\n\nescala |&gt;\n  ggplot(aes(assessment,acuracia))+\n  geom_boxplot()\n\n\n\n\nMudança na visualização de dois níveis de um fator do formato longo para o formato largo:\n\nescala2 &lt;- escala |&gt;\n  select(assessment, rater, acuracia) |&gt;\n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\nescala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 A        0.81   0.91\n 2 B        0.72   0.91\n 3 C        0.4    0.91\n 4 D        0.82   0.96\n 5 E        0.75   0.96\n 6 F        0.45   0.9 \n 7 G        0.81   0.85\n 8 H        0.78   0.88\n 9 I        0.78   0.95\n10 J        0.5    0.94\n\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nvar.test(escala2$Unaided,escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\nteste1 &lt;- t.test(escala2$Aided1, escala2$Unaided,\n                 paired = TRUE,\n                 var.equal = FALSE)\nteste1\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n\nPode-se observar no exemplo utilizando a função var.test, pelo teste F que a hipóte nula (médias são iguais) foi rejeitada. Assim, houve efeito do uso da escala diagramática pelos avaliadores."
  },
  {
    "objectID": "Aula5.html#teste-não-paramétrico",
    "href": "Aula5.html#teste-não-paramétrico",
    "title": "Teste T",
    "section": "Teste não Paramétrico",
    "text": "Teste não Paramétrico\nUm teste não paramétrico podem ser usados quando os dados não seguem uma distribuição normal.\nA função wilcox.test() é uma alternativa não paramétrica a função t.teste (Teste t de Student).\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\nWarning in wilcox.test.default(escala2$Aided1, escala2$Unaided, paired = TRUE):\nnão é possível computar o valor de p exato com o de desempate\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Aula6.html",
    "href": "Aula6.html",
    "title": "Anova com um fator",
    "section": "",
    "text": "library(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\nlibrary(ggplot2)\nmicelial |&gt;\n  ggplot(aes(especie, tcm))+\n  geom_jitter()\n\n\n\n\nA função anova() permite a observação da variabilidade em cada grupo.\nO bartlett.test() é um teste estatístico utilizado para verificar se múltiplas amostras independentes possuem variâncias homogêneas.\n\nm1 &lt;- lm(tcm ~ especie -1, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\nlibrary(multcompView)\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\nUnable to calculate quantile regression for quantile 0.25. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\nUnable to calculate quantile regression for quantile 0.5. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\nUnable to calculate quantile regression for quantile 0.75. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\nUsa-se a função count() para fazer a contagem do número de repetições (n), contagem dos insetos mortos devido a condição inseticida. Os dados apresentam apenas um fator, portanto faz-se uma anova unifatorial.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::select() masks MASS::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12"
  },
  {
    "objectID": "Aula6.html#três-tratamentos-ou-mais",
    "href": "Aula6.html#três-tratamentos-ou-mais",
    "title": "Anova com um fator",
    "section": "",
    "text": "library(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\nlibrary(ggplot2)\nmicelial |&gt;\n  ggplot(aes(especie, tcm))+\n  geom_jitter()\n\n\n\n\nA função anova() permite a observação da variabilidade em cada grupo.\nO bartlett.test() é um teste estatístico utilizado para verificar se múltiplas amostras independentes possuem variâncias homogêneas.\n\nm1 &lt;- lm(tcm ~ especie -1, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\nlibrary(multcompView)\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\nUnable to calculate quantile regression for quantile 0.25. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\nUnable to calculate quantile regression for quantile 0.5. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\nUnable to calculate quantile regression for quantile 0.75. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\nUsa-se a função count() para fazer a contagem do número de repetições (n), contagem dos insetos mortos devido a condição inseticida. Os dados apresentam apenas um fator, portanto faz-se uma anova unifatorial.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::select() masks MASS::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12"
  },
  {
    "objectID": "Aula6.html#visualização-dos-dados",
    "href": "Aula6.html#visualização-dos-dados",
    "title": "Anova com um fator",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\n\ninseticida |&gt;\n  ggplot(aes(spray, count))+\n  geom_boxplot()\n\n\n\n\nPode-se observar pelo gráfico boxplot gerado, que o eixo y mostra a contagem do número de insetos mortos, que há variabilidade, o spray F apresenta maior variância entre o grupo e o spray E menor variância. Também, pode-se observar outliers nos grupos C e D.\n\nm1 &lt;- lm(count~spray,\n         data = inseticida)\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\nlibrary(multcomp)\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m1_medias)\n\n        A       B       C       D       E       F\nA [14.50]  0.9952  &lt;.0001  &lt;.0001  &lt;.0001  0.7542\nB  -0.833 [15.33]  &lt;.0001  &lt;.0001  &lt;.0001  0.9603\nC  12.417  13.250 [ 2.08]  0.4921  0.9489  &lt;.0001\nD   9.583  10.417  -2.833 [ 4.92]  0.9489  &lt;.0001\nE  11.000  11.833  -1.417   1.417 [ 3.50]  &lt;.0001\nF  -2.167  -1.333 -14.583 -11.750 -13.167 [16.67]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m1_medias)\n\n\n\npairs(m1_medias)\n\n contrast estimate  SE df t.ratio p.value\n A - B      -0.833 1.6 66  -0.520  0.9952\n A - C      12.417 1.6 66   7.755  &lt;.0001\n A - D       9.583 1.6 66   5.985  &lt;.0001\n A - E      11.000 1.6 66   6.870  &lt;.0001\n A - F      -2.167 1.6 66  -1.353  0.7542\n B - C      13.250 1.6 66   8.276  &lt;.0001\n B - D      10.417 1.6 66   6.506  &lt;.0001\n B - E      11.833 1.6 66   7.391  &lt;.0001\n B - F      -1.333 1.6 66  -0.833  0.9603\n C - D      -2.833 1.6 66  -1.770  0.4921\n C - E      -1.417 1.6 66  -0.885  0.9489\n C - F     -14.583 1.6 66  -9.108  &lt;.0001\n D - E       1.417 1.6 66   0.885  0.9489\n D - F     -11.750 1.6 66  -7.339  &lt;.0001\n E - F     -13.167 1.6 66  -8.223  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm1$residuals\n\n          1           2           3           4           5           6 \n-4.50000000 -7.50000000  5.50000000 -0.50000000 -0.50000000 -2.50000000 \n          7           8           9          10          11          12 \n-4.50000000  8.50000000  2.50000000  5.50000000 -0.50000000 -1.50000000 \n         13          14          15          16          17          18 \n-4.33333333  1.66666667  5.66666667 -4.33333333  0.66666667 -1.33333333 \n         19          20          21          22          23          24 \n 1.66666667  1.66666667  3.66666667  5.66666667 -8.33333333 -2.33333333 \n         25          26          27          28          29          30 \n-2.08333333 -1.08333333  4.91666667 -0.08333333  0.91666667 -1.08333333 \n         31          32          33          34          35          36 \n-0.08333333 -1.08333333  0.91666667 -2.08333333 -1.08333333  1.91666667 \n         37          38          39          40          41          42 \n-1.91666667  0.08333333  7.08333333  1.08333333 -0.91666667 -1.91666667 \n         43          44          45          46          47          48 \n 0.08333333  0.08333333  0.08333333  0.08333333 -2.91666667 -0.91666667 \n         49          50          51          52          53          54 \n-0.50000000  1.50000000 -0.50000000  1.50000000 -0.50000000  2.50000000 \n         55          56          57          58          59          60 \n-2.50000000 -2.50000000 -0.50000000 -1.50000000  2.50000000  0.50000000 \n         61          62          63          64          65          66 \n-5.66666667 -7.66666667 -1.66666667  5.33333333 -1.66666667 -0.66666667 \n         67          68          69          70          71          72 \n-3.66666667 -6.66666667  9.33333333  9.33333333  7.33333333 -3.66666667 \n\nhist(m1$residuals)\n\n\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nbartlett.test(count ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\nA função lm() que significa linear model, é usado para modelar dados em uma relação linear entre a variavel dependente (resposta) e independente (tratamento).\n“~” significa em função de.\nA função summary ajuda na visualização dos dados. Observar previamente o erro-padrão, graus de liberdade, estatistica de T, e valor P. A comparação foi em relação ao tratamento A.\nA função anova() apresenta o valor de F que é o teste de análise de variância, vai determinar a variabilidade entre os grupos (se o valor calculado for maior que o tabelado, rejeita-se a hipótese nula de que as médias são iguais(P&lt;0,05)).\nA função emmeans() pode ser utilizada para vizualizar as médias e comparar este valor em cada tratamento. Dentro do pacote multicomp, há a função cld que permite visualizar os tratamentos agrupados de acordo com um teste estatistico (Tukey) no exemplo há 2 grupos formados (C, E e D) e (A, B e F), portanto há diferença entre os tratamentos, como pode-se observar na Anova.\nA função pwpm() mostra a comparação entre as médias dos tratamentos pelo teste de tukey. Triângulo superior mostra o p-valor. A diagonal mostra a média e o triângulo inferior mostra a diferença dos tratamentos em relação a média. A função pairs() também pode ser usada para a visualização dos valores de T e p- valor.\nA função pwpp() mostra a visualização do teste de Tukey em relação aos tratamentos.\nO valor dos resíduos (erro) pode ser visualizado utilizando $ (seleciona uma coluna no conjunto de dados). No exemplo, m1 é o conjunto e residuals é o que se deseja selecionar. Pode-se utilizar a função hist() para visualização a distribuiçõao dos residuos e ver se a mesma se aproxima da distribuição normal.\nAs funções qqnorm(m1$residuals) e qqline() juntas mostram um gráfico com os valores da distribuição dos resíduos em circulos e a reta dos residuos esperados. Essas funções plotam os resíduos simulados do modelo, o que pode ser útil para avaliar a adequação do modelo aos dados.\nA função shapiro.test mostra se a distribuição dos dados é normal (Se o valor estiver abaixo de 0,05 a distribuição não é considerada normal). A função check_normality() também pode ser usada para ver a normalidade dos dados.\nA função bartlett.test() mostra se as variâncias são ou não homogêneas (valor abaixo de 0,05 não é considerado homogênea). A função check_heteroscedasticity() também mostra a homogeneidade das variâncias.\nComo a distribuição do conjunto dos dados não foram normais e as variâncias não foram homogêneas, pode se utilizar alternativas para corrigir a distribuição e homogeneidade dos dados -&gt; Transformação."
  },
  {
    "objectID": "Aula8.html",
    "href": "Aula8.html",
    "title": "Anova fatorial",
    "section": "",
    "text": "A Anova fatorial é uma extensão da análise de variância que permite investigar o efeito de dois ou mais fatores categóricos e suas interações em uma variável dependente contínua.\nlibrary(gsheet)\n\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\nlibrary(ggplot2)\nli |&gt;\n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~treat)"
  },
  {
    "objectID": "Aula8.html#alternativa-1---transformação",
    "href": "Aula8.html#alternativa-1---transformação",
    "title": "Anova fatorial",
    "section": "",
    "text": "Exemplo: fazer a raiz quadrada de todos os valores para melhorar a normalidade com a função mutate() e adicionando sqrt a count.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\n\nlibrary(dplyr)\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\n\ninseticida |&gt;\n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\n\nm2 &lt;- lm(count2 ~spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans( m2, ~ spray)\nplot(m2_medias)\n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m2))\n\n\n\n#transformação Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda &lt;- 0.5\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1)/ lambda\ninseticida$count3\n\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n\n\nCom os dados transformados o teste de Shapiro-wilk mostra que a distribuição pode ser considerada normal.\nOs residuaos ficaram mais próximo ao esperado.\nNo teste de Barlett o p valor deu 58%, significa que tem-se 58% de chance de encontrar o valor determinado. Como o valor é maior que 0,05 as variâncias são consideradas homogêneas.\nteste darma mostra se os tratamentos estão dentro da variância esperada e os agrupamentos estão de acordo com a saída da anova.\nDe acordo com a anova pelo menos uma média difere das demais.\nUtilizando o pacote MASS - lambda valor de x em q y é o valor máximo (lambda 0.5 é igual a raiz quadrada)."
  },
  {
    "objectID": "Aula8.html#alternativa-2-teste-não-paramétrico",
    "href": "Aula8.html#alternativa-2-teste-não-paramétrico",
    "title": "Anova fatorial",
    "section": "Alternativa 2 teste não paramétrico",
    "text": "Alternativa 2 teste não paramétrico\nNesta alternativa pode-se trabalhar com a saida original sem transformação. Usa-se a função kruskal() quando são 3 grupos ou mais.\n\nlibrary(agricolae)\nkruskal.test(count~spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\nNa hipótese nula - Ho: médias iguais, H1: rejeita a hipotese nula que as medias são iguais.\nPelo agrupamento m3, apresenta o resultado do teste de fisher (as letrinhas), cálculo da média dos tratamentose e o ranking de ordenamento do menor para o maior. Pode-se ver nos resultados, 3 grupos - a, b e c. Resultados que batem com o boxplot gerado anteriormente.\npode-se observar que o modelo não-paramétrico apresentou o resultado igual ao paramétrico transformado."
  },
  {
    "objectID": "Aula8.html#alternativa-3---glms",
    "href": "Aula8.html#alternativa-3---glms",
    "title": "Anova fatorial",
    "section": "Alternativa 3 - GLMs",
    "text": "Alternativa 3 - GLMs\nO modelo 4 não assume a distribuição normal. Portanto, usa-se um modelo diferente: modelo linear generalizado.\n\nm4 &lt;- glm(count ~spray,\n          family = poisson,\n          data = inseticida)\nm4\n\n\nCall:  glm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n    2.67415      0.05588     -1.94018     -1.08152     -1.42139      0.13926  \n\nDegrees of Freedom: 71 Total (i.e. Null);  66 Residual\nNull Deviance:      409 \nResidual Deviance: 98.33    AIC: 376.6\n\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\nm4_medias &lt;- emmeans(m4, ~spray,\n                     type = \"response\")\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nIsso ajusta um modelo de regressão Poisson onde a variável dependente é count e a variável independente é spray, usando os dados contidos no dataframe inseticida.\nA função anova() realiza uma análise de variância do modelo, que é útil para determinar a significância global do modelo de regressão Poisson.\nComo resultados, observa-se diferença estatística e as variâncias são homogêneas (diferente do original).\nFunção emmeans() - calcula o log, response=dados originais (14, 50, 95% das vezes dentro do intervalo)."
  },
  {
    "objectID": "Aula7.html",
    "href": "Aula7.html",
    "title": "Transformação dos dados",
    "section": "",
    "text": "Exemplo: fazer a raiz quadrada de todos os valores para melhorar a normalidade com a função mutate() e adicionando sqrt a count.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\n\nlibrary(dplyr)\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\n\ninseticida |&gt;\n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\n\nm2 &lt;- lm(count2 ~spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans( m2, ~ spray)\nplot(m2_medias)\n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m2))\n\n\n\n#transformação Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda &lt;- 0.5\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1)/ lambda\ninseticida$count3\n\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n\n\nCom os dados transformados o teste de Shapiro-wilk mostra que a distribuição pode ser considerada normal.\nOs residuaos ficaram mais próximo ao esperado.\nNo teste de Barlett o p valor deu 58%, significa que tem-se 58% de chance de encontrar o valor determinado. Como o valor é maior que 0,05 as variâncias são consideradas homogêneas.\nteste darma mostra se os tratamentos estão dentro da variância esperada e os agrupamentos estão de acordo com a saída da anova.\nDe acordo com a anova pelo menos uma média difere das demais.\nUtilizando o pacote MASS - lambda valor de x em q y é o valor máximo (lambda 0.5 é igual a raiz quadrada)."
  },
  {
    "objectID": "Aula7.html#alternativa-1---transformação",
    "href": "Aula7.html#alternativa-1---transformação",
    "title": "Transformação dos dados",
    "section": "",
    "text": "Exemplo: fazer a raiz quadrada de todos os valores para melhorar a normalidade com a função mutate() e adicionando sqrt a count.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\n\nlibrary(dplyr)\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\n\ninseticida |&gt;\n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\n\nm2 &lt;- lm(count2 ~spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans( m2, ~ spray)\nplot(m2_medias)\n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m2))\n\n\n\n#transformação Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda &lt;- 0.5\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1)/ lambda\ninseticida$count3\n\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n\n\nCom os dados transformados o teste de Shapiro-wilk mostra que a distribuição pode ser considerada normal.\nOs residuaos ficaram mais próximo ao esperado.\nNo teste de Barlett o p valor deu 58%, significa que tem-se 58% de chance de encontrar o valor determinado. Como o valor é maior que 0,05 as variâncias são consideradas homogêneas.\nteste darma mostra se os tratamentos estão dentro da variância esperada e os agrupamentos estão de acordo com a saída da anova.\nDe acordo com a anova pelo menos uma média difere das demais.\nUtilizando o pacote MASS - lambda valor de x em q y é o valor máximo (lambda 0.5 é igual a raiz quadrada)."
  },
  {
    "objectID": "Aula7.html#alternativa-2-teste-não-paramétrico",
    "href": "Aula7.html#alternativa-2-teste-não-paramétrico",
    "title": "Transformação dos dados",
    "section": "Alternativa 2 teste não paramétrico",
    "text": "Alternativa 2 teste não paramétrico\nNesta alternativa pode-se trabalhar com a saida original sem transformação. Usa-se a função kruskal() quando são 3 grupos ou mais.\n\nlibrary(agricolae)\nkruskal.test(count~spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\nNa hipótese nula - Ho: médias iguais, H1: rejeita a hipotese nula que as medias são iguais.\nPelo agrupamento m3, apresenta o resultado do teste de fisher (as letrinhas), cálculo da média dos tratamentose e o ranking de ordenamento do menor para o maior. Pode-se ver nos resultados, 3 grupos - a, b e c. Resultados que batem com o boxplot gerado anteriormente.\npode-se observar que o modelo não-paramétrico apresentou o resultado igual ao paramétrico transformado."
  },
  {
    "objectID": "Aula7.html#alternativa-3---glms",
    "href": "Aula7.html#alternativa-3---glms",
    "title": "Transformação dos dados",
    "section": "Alternativa 3 - GLMs",
    "text": "Alternativa 3 - GLMs\nO modelo 4 não assume a distribuição normal. Portanto, usa-se um modelo diferente: modelo linear generalizado.\n\nm4 &lt;- glm(count ~spray,\n          family = poisson,\n          data = inseticida)\nm4\n\n\nCall:  glm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n    2.67415      0.05588     -1.94018     -1.08152     -1.42139      0.13926  \n\nDegrees of Freedom: 71 Total (i.e. Null);  66 Residual\nNull Deviance:      409 \nResidual Deviance: 98.33    AIC: 376.6\n\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\nm4_medias &lt;- emmeans(m4, ~spray,\n                     type = \"response\")\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nIsso ajusta um modelo de regressão Poisson onde a variável dependente é count e a variável independente é spray, usando os dados contidos no dataframe inseticida.\nA função anova() realiza uma análise de variância do modelo, que é útil para determinar a significância global do modelo de regressão Poisson.\nComo resultados, observa-se diferença estatística e as variâncias são homogêneas (diferente do original).\nFunção emmeans() - calcula o log, response=dados originais (14, 50, 95% das vezes dentro do intervalo)."
  },
  {
    "objectID": "Aula8.html#anova-fatorial",
    "href": "Aula8.html#anova-fatorial",
    "title": "Anova fatorial",
    "section": "",
    "text": "A Anova fatorial é uma extensão da análise de variância que permite investigar o efeito de dois ou mais fatores categóricos e suas interações em uma variável dependente contínua.\n\nlibrary(gsheet)\n\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\n\nlibrary(ggplot2)\nli |&gt;\n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~treat)"
  },
  {
    "objectID": "Aula8.html#modelo-fatorialtwo-way-anova",
    "href": "Aula8.html#modelo-fatorialtwo-way-anova",
    "title": "Anova fatorial",
    "section": "Modelo fatorial(two-way anova)",
    "text": "Modelo fatorial(two-way anova)\nFatorial testa a interação entre os tratamentos.\n\nmf &lt;- lm(severity ~treat*factor(dose),\n         data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(mf))\n\nUnable to calculate quantile regression for quantile 0.25. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\nUnable to calculate quantile regression for quantile 0.5. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\nUnable to calculate quantile regression for quantile 0.75. Possibly to few (unique) data points / predictions. Will be ommited in plots and significance calculations.\n\n\n\n\nlibrary(emmeans)\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\nmf_medias\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.2921 0.0273 16  0.23420   0.3500\n  2.0 0.0501 0.0273 16 -0.00781   0.1080\n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.0210 0.0273 16 -0.03690   0.0789\n  2.0 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nshapiro.test(mf$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mf$residuals\nW = 0.86792, p-value = 0.0108\n\n\nO exemplo mostra se é significativo o efeito da dose no tratamento (estimar as médias de um dentro do outro)."
  },
  {
    "objectID": "Aula9.html",
    "href": "Aula9.html",
    "title": "Anova com DBC",
    "section": "",
    "text": "Delineamento experimental que contém o terceiro príncipio da experimentação, que é o controle local. Este delineamento reduz as fontes de variação, com isso o erro experimental também é reduzido (não favorece um tratamento em detrimento de outro)."
  },
  {
    "objectID": "Aula9.html#anova-com-blocos-casualizados",
    "href": "Aula9.html#anova-com-blocos-casualizados",
    "title": "Anova com DBC",
    "section": "",
    "text": "Delineamento experimental que contém o terceiro príncipio da experimentação, que é o controle local. Este delineamento reduz as fontes de variação, com isso o erro experimental também é reduzido (não favorece um tratamento em detrimento de outro)."
  },
  {
    "objectID": "Aula9.html#importar-os-dados",
    "href": "Aula9.html#importar-os-dados",
    "title": "Anova com DBC",
    "section": "Importar os dados",
    "text": "Importar os dados\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nsoja &lt;- soja |&gt;\n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))"
  },
  {
    "objectID": "Aula9.html#visualizar-os-dados",
    "href": "Aula9.html#visualizar-os-dados",
    "title": "Anova com DBC",
    "section": "Visualizar os dados",
    "text": "Visualizar os dados\n\ndfc&lt;- soja |&gt;\n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width= 0.05, color=\n                \"gray70\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"black\", alpha= 0.05)\ndfc\n\n\n\nfer &lt;- soja |&gt;\n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width= 0.05, color=\n                \"gray70\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"black\", alpha= 0.05)\nfer\n\n\n\nprod &lt;- soja |&gt;\n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width= 0.05, color=\n                \"gray70\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"black\", alpha= 0.05)\nprod\n\n\n\nlibrary(ggpubr)\nggarrange(dfc,fer,prod, ncol=3,nrow=1)"
  },
  {
    "objectID": "Aula9.html#anova-para-a-variável-dfc",
    "href": "Aula9.html#anova-para-a-variável-dfc",
    "title": "Anova com DBC",
    "section": "Anova para a variável DFC",
    "text": "Anova para a variável DFC\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(writexl)\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld2 &lt;- cld(medias_dfc, Letters = LETTERS)\nwrite_xlsx (cld2, \"df.xlsx\" )"
  },
  {
    "objectID": "Aula9.html#anova-para-a-variável-fer",
    "href": "Aula9.html#anova-para-a-variável-fer",
    "title": "Anova com DBC",
    "section": "Anova para a variável FER",
    "text": "Anova para a variável FER\n\naov_fer &lt;- lm(FER2 &lt;- log(FER) ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: log(FER)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.035).\n\ncheck_normality(aov_fer)\n\nOK: residuals appear as normally distributed (p = 0.255).\n\nlibrary(emmeans)\nmedias_fer &lt;- emmeans(aov_fer, ~TRAT, type = \"response\")\nmedias_fer\n\n TRAT response    SE df lower.CL upper.CL\n 1       20.02 1.959 21    16.33    24.54\n 2        5.68 0.556 21     4.63     6.96\n 3        3.81 0.373 21     3.11     4.67\n 4        3.08 0.301 21     2.51     3.78\n 5        3.24 0.317 21     2.64     3.97\n 6        2.98 0.292 21     2.43     3.65\n 7        3.37 0.330 21     2.75     4.13\n 8        3.48 0.341 21     2.84     4.27\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7       8\n1 [20.02]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   3.525 [ 5.68]  0.1252  0.0048  0.0110  0.0028  0.0204  0.0343\n3   5.259   1.492 [ 3.81]  0.7832  0.9335  0.6440  0.9843  0.9976\n4   6.500   1.844   1.236 [ 3.08]  0.9999  1.0000  0.9976  0.9842\n5   6.178   1.753   1.175   0.951 [ 3.24]  0.9984  1.0000  0.9994\n6   6.721   1.906   1.278   1.034   1.088 [ 2.98]  0.9842  0.9431\n7   5.945   1.686   1.130   0.915   0.962   0.885 [ 3.37]  1.0000\n8   5.750   1.631   1.093   0.885   0.931   0.856   0.967 [ 3.48]\n\nRow and column labels: TRAT\nUpper triangle: P values   null = 1  adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (ratio)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer, Letters = LETTERS)\n\n TRAT response    SE df lower.CL upper.CL .group\n 6        2.98 0.292 21     2.43     3.65  A    \n 4        3.08 0.301 21     2.51     3.78  A    \n 5        3.24 0.317 21     2.64     3.97  A    \n 7        3.37 0.330 21     2.75     4.13  A    \n 8        3.48 0.341 21     2.84     4.27  A    \n 3        3.81 0.373 21     3.11     4.67  AB   \n 2        5.68 0.556 21     4.63     6.96   B   \n 1       20.02 1.959 21    16.33    24.54    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 8 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nb &lt;- boxcox(lm(soja$FER ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER2 &lt;- (soja$FER ^lambda - 1) / lambda"
  },
  {
    "objectID": "Aula9.html#anova-para-a-variável-prod",
    "href": "Aula9.html#anova-para-a-variável-prod",
    "title": "Anova com DBC",
    "section": "Anova para a variável PROD",
    "text": "Anova para a variável PROD\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\n\nlibrary(agricolae)\ncv.model(aov_prod)\n\n[1] 8.057402\n\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\nlibrary(emmeans)\nmedias_prod &lt;- emmeans(aov_prod, ~TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\nmedias_prod_grupo &lt;- cld(medias_prod, Letters = LETTERS)\nmedias_prod_grupo\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html#visualização-das-médias-e-barra-de-erro.",
    "href": "Aula9.html#visualização-das-médias-e-barra-de-erro.",
    "title": "Anova com DBC",
    "section": "Visualização das médias e barra de erro.",
    "text": "Visualização das médias e barra de erro.\nO pacote writexl e função write_xlsx() permitem exportar data frames para o formato Excel, permitindo que os dados sejam facilmente compartilhados e analisados em outras plataformas.\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt;\n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\nannotate(geom = \"text\", x = 1.2, y = 4200,\n         label = \"A\")\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")"
  },
  {
    "objectID": "Aula9.html#dados-de-severidade",
    "href": "Aula9.html#dados-de-severidade",
    "title": "Anova com DBC",
    "section": "Dados de severidade",
    "text": "Dados de severidade\n\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\n\ncurve |&gt; \n  group_by(day, Irrigation) |&gt; \n  summarise(mean_sev = mean(severity)) |&gt; \n  ggplot(aes(day, mean_sev)) +\n   geom_point(which = 0.05)+ \n  geom_line()+\n  facet_wrap(~~Irrigation)\n\n`summarise()` has grouped output by 'day'. You can override using the `.groups`\nargument.\n\n\nWarning in geom_point(which = 0.05): Ignoring unknown parameters: `which`"
  },
  {
    "objectID": "Aula9.html#cálculo-da-área-abaixo-da-curva-de-progressoo-da-doença-aacpd",
    "href": "Aula9.html#cálculo-da-área-abaixo-da-curva-de-progressoo-da-doença-aacpd",
    "title": "Anova com DBC",
    "section": "Cálculo da Área Abaixo da Curva de progressoo da Doença (AACPD)",
    "text": "Cálculo da Área Abaixo da Curva de progressoo da Doença (AACPD)\nCriando uma nova variável na planilha (chamada AACPD). Então, pode-se calcular a anova a partir dessa variável (AACPD).\n\nlibrary(epifitter)\ncurve2 &lt;- curve |&gt;\n  group_by(Irrigation, rep) |&gt;\n  summarise(aacpd = AUDPC(day,severity))\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\nm_curve &lt;- lm(aacpd ~Irrigation + factor(rep),\n              data = curve2)\n\nanova(m_curve) \n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(agricolae)\ncv.model(m_curve)\n\n[1] 1.097572"
  }
]